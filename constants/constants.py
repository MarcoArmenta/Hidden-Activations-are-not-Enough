ARCHITECTURES = [# 0
                 (500, 500, 500, 500, 500),
                 # 1
                 (1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000),
                 # 2
                 (1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,
                  1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000),
                 # 3
                 (10000, 10000),
                 # 4
                 (10000, 10000, 10000, 10000, 10000),
                 # 5
                 (10000, 9000, 8000, 7000, 6000, 5000, 4000, 3000, 2000, 1000),
                 # 6
                 (675000, 1500, 1500, 1500, 1500)
                 ]

# TODO: Train BIG mlp for a lot of time
# TODO: pretrained mlps on the internet

ATTACKS = ["GN", "FGSM", "RFGSM", "PGD", "EOTPGD", "FFGSM", "TPGD", "MIFGSM", "UPGD", "DIFGSM", "NIFGSM",
           "PGDRS", "SINIFGSM", "VMIFGSM", "VNIFGSM", "CW", "PGDL2", "PGDRSL2", "DeepFool", "SparseFool",
           "OnePixel", "Pixle", "FAB"]

DEFAULT_EXPERIMENTS = {
    'experiment_0': {
        'architecture_index': 0,
        'dataset': 'mnist',
        'optimizer': 'sgd',
        'lr': 0.01,
        'batch_size': 8,
        'epoch': 1,
        'reduce_lr_each': 5,
        'save_every_epochs': 2,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_1': {
        'architecture_index': 0,
        'optimizer': 'momentum',
        'dataset': 'mnist',
        'lr': 0.01,
        'batch_size': 32,
        'epoch': 11,
        'reduce_lr_each': 5,
        'save_every_epochs': 2,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_2': {
        'architecture_index': 0,
        'optimizer': 'adam',
        'dataset': 'fashion',
        'lr': 1e-06,
        'batch_size': 32,
        'epoch': 81,
        'reduce_lr_each': 20,
        'save_every_epochs': 10,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_3': {
        'architecture_index': 0,
        'optimizer': 'sgd',
        'dataset': 'fashion',
        'lr': 0.1,
        'batch_size': 16,
        'epoch': 51,
        'reduce_lr_each': 20,
        'save_every_epochs': 10,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_4': {
        'architecture_index': 1,
        'optimizer': 'momentum',
        'dataset': 'mnist',
        'lr': 0.01,
        'batch_size': 32,
        'epoch': 7,
        'reduce_lr_each': 5,
        'save_every_epochs': 2,
        'residual': True,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_5': {
        'architecture_index': 1,
        'optimizer': 'momentum',
        'dataset': 'fashion',
        'lr': 0.01,
        'batch_size': 32,
        'epoch': 11,
        'reduce_lr_each': 5,
        'save_every_epochs': 5,
        'residual': True,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_6': {
        'architecture_index': 1,
        'optimizer': 'adam',
        'dataset': 'mnist',
        'lr': 0.001,
        'batch_size': 128,
        'epoch': 6,
        'reduce_lr_each': 3,
        'save_every_epochs': 2,
        'residual': True,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_7': {
        'architecture_index': 2,
        'optimizer': 'adam',
        'dataset': 'fashion',
        'lr': 0.0001,
        'batch_size': 16,
        'epoch': 41,
        'reduce_lr_each': 5,
        'save_every_epochs': 5,
        'residual': True,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_8': {
        'architecture_index': 2,
        'optimizer': 'adam',
        'dataset': 'mnist',
        'lr': 0.0001,
        'batch_size': 16,
        'epoch': 41,
        'reduce_lr_each': 5,
        'save_every_epochs': 5,
        'residual': True,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_9': {
        'architecture_index': 2,
        'optimizer': 'adam',
        'dataset': 'fashion',
        'lr': 0.001,
        'batch_size': 16,
        'epoch': 11,
        'reduce_lr_each': 5,
        'save_every_epochs': 5,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_10': {
        'architecture_index': 3,
        'optimizer': 'momentum',
        'dataset': 'mnist',
        'lr': 0.01,
        'batch_size': 32,
        'epoch': 1,
        'reduce_lr_each': 5,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_11': {
        'architecture_index': 3,
        'optimizer': 'momentum',
        'dataset': 'fashion',
        'lr': 0.01,
        'batch_size': 32,
        'epoch': 11,
        'reduce_lr_each': 5,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_12': { #overfits 99 train vs 60 test
        'architecture_index': 3,
        'optimizer': 'momentum',
        'dataset': 'cifar10',
        'lr': 0.01,
        'batch_size': 64,
        'epoch': 101,
        'reduce_lr_each': 20,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 1e-5,
        'dropout': True,
    },
    'experiment_13': {
        'architecture_index': 4,
        'optimizer': 'sgd',
        'dataset': 'mnist',
        'lr': 0.01,
        'batch_size': 64,
        'epoch': 6,
        'reduce_lr_each': 20,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_14': {
        'architecture_index': 4,
        'optimizer': 'sgd',
        'dataset': 'fashion',
        'lr': 0.01,
        'batch_size': 64,
        'epoch': 16,
        'reduce_lr_each': 20,
        'save_every_epochs': 5,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_15': { #overfits: 97.3 vs 57.78
        'architecture_index': 4,
        'optimizer': 'adam',
        'dataset': 'cifar10',
        'lr': 0.001,
        'batch_size': 256,
        'epoch': 201,
        'reduce_lr_each': 40,
        'save_every_epochs': 10,
        'residual': False,
        'weight_decay': 1e-5,
        'dropout': True,
    },
    'experiment_16': { #TODO: check performance
        'architecture_index': 5,
        'optimizer': 'sgd',
        'dataset': 'mnist',
        'lr': 0.01,
        'batch_size': 16,
        'epoch': 10,
        'reduce_lr_each': 40,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_17': { #TODO: check performance
        'architecture_index': 5,
        'optimizer': 'sgd',
        'dataset': 'fashion',
        'lr': 0.01,
        'batch_size': 128,
        'epoch': 21,
        'reduce_lr_each': 5,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_18': { #TODO: check performance
        'architecture_index': 5,
        'optimizer': 'adam',
        'dataset': 'cifar10',
        'lr': 0.001,
        'batch_size': 256,
        'epoch': 201,
        'reduce_lr_each': 40,
        'save_every_epochs': 50,
        'residual': False,
        'weight_decay': 1e-5,
        'dropout': True,
    },
    'experiment_19': { #TODO: this only trains on 40 GBs GPU
        'architecture_index': 6,
        'optimizer': 'sgd',
        'dataset': 'cifar10',
        'lr': 0.001,
        'batch_size': 128,
        'epoch': 301,
        'reduce_lr_each': 40,
        'save_every_epochs': 10,
        'residual': False,
        'weight_decay': 1e-5,
        'dropout': True,
    },
    'experiment_20': { #TODO: this only trains on 40 GBs GPU
        'architecture_index': 6,
        'optimizer': 'momentum',
        'dataset': 'mnist',
        'lr': 0.001,
        'batch_size': 128,
        'epoch': 11,
        'reduce_lr_each': 40,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 1e-5,
        'dropout': True,
    },
    'experiment_21': { #TODO: this only trains on 40 GBs GPU
        'architecture_index': 6,
        'optimizer': 'momentum',
        'dataset': 'fashion',
        'lr': 0.001,
        'batch_size': 128,
        'epoch': 11,
        'reduce_lr_each': 40,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 1e-5,
        'dropout': True,
    },
    'experiment_22': { #TODO: this only trains on 40 GBs GPU
        'architecture_index': 7,
        'optimizer': 'momentum',
        'dataset': 'mnist',
        'lr': 0.001,
        'batch_size': 256,
        'epoch': 11,
        'reduce_lr_each': 40,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    },
    'experiment_23': { #TODO: this only trains on 40 GBs GPU
        'architecture_index': 7,
        'optimizer': 'momentum',
        'dataset': 'fashion',
        'lr': 0.001,
        'batch_size': 256,
        'epoch': 11,
        'reduce_lr_each': 5,
        'save_every_epochs': 1,
        'residual': False,
        'weight_decay': 0,
        'dropout': False,
    }
}